{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人工神经元\n",
    "\n",
    "<img src=\"../img/neurl.png\" style=\"zoom:33%;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Linear 线性层\n",
    "\n",
    "线性层 (Linear Layer) 又称 全连接层 (Full-connected Layer)，其每个神经元与上一层所有神经元相连，实现对前一层的 线性组合/线性变换。每个神经元都和前一层中的所有神经元相连，每个神经元的计算方式是对上一层的加权求和的过程。因此，线性层可以采用矩阵乘法来实现。\n",
    "\n",
    "\n",
    "<img src=\"../img/linear.png\" style=\"zoom:33%;\" />\n",
    "\n",
    "\n",
    "**计算公式：**\n",
    "$$y = xW^{T} + bias$$\n",
    "\n",
    "**主要参数：**\n",
    "+ in_features：输入结点数\n",
    "+ out_features：输出结点数\n",
    "+ bias：是否需要偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 30])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.Linear(in_features, out_features, bias=True)\n",
    "layer = nn.Linear(20, 30)\n",
    "x = torch.randn(128, 20)\n",
    "y = layer(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数层\n",
    "\n",
    "激活函数 (Activation Function) 是对特征进行非线性变换，赋予多层神经网络具有**深度**的意义\n",
    "\n",
    "<img src=\"../img/acf.png\" style=\"zoom:33%;\" />\n",
    "\n",
    "在上面最后一步中，由于矩阵乘法的结合性，我们可以把右边三个权重矩阵先结合相乘，可以得到一个大的权重矩阵$W$。这样我们可以看到，我们的输出实际上就是输入$X$乘以一个大的权重矩阵$W$。\n",
    "\n",
    "因此，这里的三层线性全连接层实际上等价于一个一层的全连接层，这是由于线性运算当中矩阵乘法的结合性导致的\n",
    "\n",
    "如果加上**非线性激活函数**，这一结论将不再成立，因此我们说，激活函数赋予了多层神经网络具有**深度**意义。\n",
    "\n",
    "**不同的激活函数：**\n",
    "\n",
    "<img src=\"../img/acf2.png\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2., -1.,  0.,  1.,  2.])\n",
      "tensor([0., 0., 0., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "X = torch.linspace(-2, 2, 5)\n",
    "relu = nn.ReLU()\n",
    "y = relu(X)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多层网络\n",
    "\n",
    "例子：两层全连接网络\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(2, 20)\n",
    "net = nn.Sequential(nn.Linear(20, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256, 10))\n",
    "y = net(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "我们希望模型的输出 $y_i$ 可以视为输入 $x_i$ 经过网络后计算出属于类$i$的概率，然后选择具有最大输出值的类别 $i$ 作为我们的预测标签\n",
    "\n",
    "+ 没有限制这些输出数字的总和为1\n",
    "+ 根据输入的不同，输出可以为负值\n",
    "\n",
    "<img src=\"../img/softmax.png\" style=\"zoom:33%;\" />\n",
    "\n",
    "$p_i = softmax(z_i) = \\frac{e^{z_i}}{\\Sigma_j e^{z_i}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5914, 0.0800, 0.0040, 0.3246])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([3, 1, -2, 2.4])\n",
    "soft = nn.Softmax(dim=0)\n",
    "y = soft(X)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN 人工神经网络\n",
    "\n",
    "<img src=\"../img/ann.png\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n",
      "tensor([[0.5493, 0.4507]], grad_fn=<SoftmaxBackward0>) torch.Size([1, 2])\n",
      "Linear(in_features=784, out_features=300, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# 构建三层的ANN人工神经网络 / 全连接神经网络 Full Connected Neural Network\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 输入层的输入\n",
    "x = torch.randn(28, 28, 1).reshape(1, 784)\n",
    "\n",
    "# 隐藏层1 -> 隐藏层2 -> 输出\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(in_features=784, out_features=300),\n",
    "    nn.ReLU(),  # 激活函数\n",
    "    nn.Linear(in_features=300, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=100, out_features=2),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# 将输入传给神经网络, 生成的输出(预测值/概率值)\n",
    "y = network(x)\n",
    "\n",
    "print(network)\n",
    "print(y, y.size())\n",
    "# 输出自动初始化的权重weights, 偏置bias\n",
    "print(network[0])\n",
    "# 获取 (0): Linear(in_features=784, out_features=300, bias=True)的所有状态字典\n",
    "print(network[0].state_dict()) \n",
    "print(network[0].weight.size(), network[0].weight)\n",
    "print(network[0].bias.size(), network[0].bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
